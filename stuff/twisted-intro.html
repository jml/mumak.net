<html>
  <head>
    <title>Everything You Always Wanted to Know about Twisted</title>
  </head>
  <body>

    <p>
      <i>This paper is here for historical purposes only.  As
          of <a href="http://labs.twistedmatrix.com/2013/04/on-behalf-of-twisted-matrix.html">Twisted
          13.0.0</a>,
          a <a href="http://twistedmatrix.com/documents/current/core/howto/defer-intro.html">better
          version</a> is included as part of the core Twisted
          documentation.</i></p>

    <p><i>This paper was originally prepared as an introduction to Twisted for
        the Launchpad development team, and was presented in London on October
        30th, 2008. The version here has been edited for HTML, and has had
        Launchpad-specific references and examples removed.</i></p>

    <p>
      By Jonathan M. Lange & Michael Hudson.
    </p>

<h1>Abstract</h1>

<p>
Twisted has a bit of a reputation of being <q>magic</q> and some people seem
to be a bit scared of it. This talk will aim to explain the basic ideas of
Twisted in simple language and make it clear that it is not at all magic. It
will touch on the reactor, Deferreds, basic protocol structure and dispell
some common misconceptions.
</p>

<h1>Introduction</h1>

<p>
Twisted is, at its heart, an asynchronous I/O framework written in Python. It
comes bundled with application servers, defunct persistence systems, protocol
implementations, a testing framework and a quotes file. Its size, scope and
the unfamiliarity of its concepts make it intimidating for newcomers. This
paper aims to address the latter point, by explaining the concepts of
asynchronous programming as implemented by Twisted.
</p>

<p>
This paper assumes that you know how to write Python code, that you know
roughly what an event loop is, and that you are comfortable with network
programming in general. When you are finished, you should know enough about
Twisted to start investigating how you can use it to solve your specific
problems.
</p>

<h1>A Result You Don't Have Yet</h1>

<p>
Imagine that you are writing a program where one API that you are using
returns placeholders for the actual results. You could think of each
placeholder as a promise that you will eventually get a result or you could
think of them as a result that you don't have yet.
</p>

<p>
Suppose one of these functions was order_food(). This function places an order
for some food and then returns immediately. When we call it, it returns a
placeholder, like so:
</p>

<pre class="python">
PLACEHOLDER = order_food()
</pre>

<p>
We have the placeholder now and sometime later we'll get the actual response
(e.g. eggs benedict). How can we write a program that depends on the outcome
of ordering food? To do this, we would need to be able to schedule actions for
when we get the actual response. So, something like:
</p>

<pre class="python">
PLACEHOLDER = order_food()
When PLACEHOLDER is ready, do ACTION
</pre>

<p>
In Python, PLACEHOLDER is going to be a Python object, and the ACTION is
best represented as a callable, giving us::
</p>

<pre class="python">
placeholder = order_food()
placeholder.when_ready(do_action)
</pre>

<p>
You can think of PLACEHOLDER as the source of a single event: "got a value"
and <code>do_action</code> a handler for that event. If order_food just
returned its result immediately, the code would look like:
</p>

<pre class="python">
value = order_food()
do_action(value)
</pre>

<p>
But our placeholder is not yet good enough. We need a way to use the result of
<code>do_action</code> to do other things. We need an equivalent of::
</p>

<pre class="python">
value = order_food()
x = do_action(value)
do_something_else(x)
</pre>

<p>
That is, our placeholder needs to do something like::
</p>

<pre class="python">
placeholder = order_food()
placeholder.when_ready(do_action)
placeholder.when_ready(do_something_else)
</pre>

<p>
Where the return value of <code>do_action</code> is passed to
do_something_else.
</p>

<p>
To illustrate, let's extend our example to do something interesting with the
food we get back.
</p>

<pre class="python">
    placeholder = order_food()
    placeholder.when_ready(eat_meal)
    placeholder.when_ready(compliment_chef)

    def eat_meal(meal):
        # I don't know how to do this in Python.
        was_it_good = nom_nom_nom(meal)
        return was_it_good

    def compliment_chef(praiseworthy):
        if praiseworthy:
            print "Wuu chef!"
        else:
            print "I sneeze in your face!"
</pre>

<p>
  <code>eat_meal</code> and <code>compliment_chef</code> are
  both <q>callbacks</q>. <code>eat_meal</code> is run as soon as we have a
  real result for <code>order_food()</code>. It's passed that result
  (<code>meal</code> in the example), eats it and then returns a boolean
  indicating whether or not it was any good. The key here is that
  <em>the return value of a callback is passed as the first parameter to the
  next callback.</em>
</p>

<p>
  <code>compliment_chef</code> is run as soon as submit_to_pqm finishes. It is
  passed the return value of <code>eat_meal</code>.
</p>

<p>
  If <code>order_food</code> returned its result immediately, the code would
  look like:
</p>

<pre class="python">
meal = order_food()
was_it_good = nom_nom_nom(meal):
if was_it_good:
    print "Wuu chef!"
else:
    print "I sneeze in your face!"
</pre>

<h2>No Magic</h2>

<p>
  So far, there is no magic involved, just pure Python abstraction: no threads,
  no I/O, no subprocesses, no signals, no concurrency.</p>

<p>In fact, here's an implementation:</p>

<pre class="python">
class Placeholder:
    """A value you don't yet have."""
    UNFIRED = object()

    def __init__(self):
        self._callbacks = []
        self._result = self.UNFIRED

    def already_fired(self):
        return not self._result is self.UNFIRED

    def when_ready(self, callable, *args,
                   **kwargs):
        self._callbacks.append((callable, args, kwargs))
        if self.already_fired():
            self._run_callbacks()
        return self

    def _run_callbacks(self):
        while self._callbacks:
            callable, args, kwargs = self._callbacks.pop()
            self._result = callable(self._result, *args, **kwargs)

    def fire(self, value):
        if self.already_fired():
            raise AlreadyFiredError(
                self, value)
        self._result = value
        self._run_callbacks()
</pre>

<p>Nothing special, just loops, lists and first-class functions.</p>

<p>
The reader will notice three things about this implementation:

<ol>
  <li>
    If a callback takes a long time to execute, the _run_callbacks loop will
    block.
  </li>
  <li>There is no error handling.</li>
  <li>If a callback returns a placeholder itself, the callbacks of *that*
    placeholder will never be run</li>
</ol>

The first is a deliberate design decision: there is no magic here. The second
is the subject of the next section. The third is left as an exercise to the
reader (hint: you can cheat by looking inside twisted/internet/defer.py).
</p>

<h2>Errors</h2>

<p>
Actually, a placeholder is the source of two events: success and failure,
which correspond to 'return' and 'raise'. Any placeholder can stand for a
successful result or for a raised error.
</p>

<p>
This means that we need the equivalents of::
</p>

<pre class="python">
# 1. Handle error then do the action anyway.
try:
    value = order_food()
except:
    handle_error()
do_action(value)
</pre>

<pre class="python">
# 2. Handle the error but do the action only if the error doesn't occur.
try:
    value = order_food()
except:
    handle_error()
else:
    do_action(value)
</pre>

<pre class="python">
# 3. Handle the error for the entire operation.
try:
    value = order_food()
    do_action(value)
except:
    handle_error()
</pre>

<pre class="python">
# 4. Do something regardless of success or failure.
try:
    value = order_food()
finally:
    do_cleanup()
</pre>

<p>
We simply cannot use Python's built-in exception handling structures because
the result is not known yet. We need to extend our placeholder to be able to
replicate any error handling that we can do with try/except/else/finally.
Luckily, Twisted has already implemented such a placeholder, calling it a
Deferred. The 'when_ready' operation described above is called 'addCallback',
and is analogous to 'do this on next success'. The example from the previous
section becomes:
</p>

<pre class="python">
deferred = order_food()
deferred.addCallback(eat_meal)
deferred.addCallback(compliment_chef)
</pre>

<p>
addCallback has a sibling, 'addErrback', which is 'do this on next failure'.
</p>

<p>
The four clauses above become:
</p>

<pre class="python">
# 1. Handle error then do the action anyway.
deferred = order_food()
deferred.addErrback(handle_error)
deferred.addCallback(do_action)
</pre>

<pre class="python">
# 2. Handle the error but do the action only if
# the error doesn't occur.
deferred = order_food()
deferred.addCallbacks(do_action, handle_error)
</pre>

<pre class="python">
# 3. Handle the error for the entire operation.
deferred = order_food()
deferred.addCallback(do_action)
deferred.addErrback(handle_error)
</pre>

<pre class="python">
# 4. Do something regardless of success or failure.
deferred = order_food()
deferred.addBoth(do_cleanup)
</pre>

<p>
  Again, <em>none of this requires magic.</em> We could make the "Placeholder"
example above handle all of these cases without introducing any concurrency,
threading or non-blocking I/O.
</p>

<p>
We now have everything we need to write programs that use results that we
don't have yet. The only thing we lack is a <em>reason</em> for using such
results. For that we need a way of implementing asynchronous operations.
</p>

<h1>The Reactor</h1>

<p>
The reactor is Twisted's event loop. You use the reactor to register sources
of events and handlers for these events, and then the reactor calls those
handlers.
</p>

<p>
In this sense, the simplest possible Twisted program is:
</p>

<pre class="python">
from twisted.internet import reactor

print 'Hello'
reactor.run()
</pre>

<p>
This will print 'Hello' and then run until it is interrupted with a signal
(another event).
</p>

<p>
We can make the program a little more complex by registering our own event:
</p>

<pre class="python">
from twisted.internet import reactor

def print_world():
    print 'World!'

print 'Hello ',
reactor.callWhenRunning(print_world)
reactor.run()
</pre>

<p>
The reactor will print 'Hello', and then print 'World!' once it starts
running, and then it will loop forever as before.  The next simplest form of
event is based on elapsed time:
</p>

<pre class="python">
from twisted.internet import reactor

def print_world():
    print 'World!'
    reactor.callLater(5, reactor.stop)

print 'Hello ',
reactor.callWhenRunning(print_world)
reactor.run()
</pre>

<p>
This will print "Hello, World!" as above, and then wait five seconds before
shutting down the reactor and exiting cleanly.
</p>

<p>
Note that the reactor calls your code and when your code is done, control
returns to the reactor.
</p>

<p>
Deferreds are used in order to turn event handlers into APIs that are
independent of those events:
</p>

<pre class="python">
from twisted.internet import defer, reactor

def run_later(seconds, function, *args, **kwargs):
    d = defer.Deferred()
    def fire():
        value = function(*args, **kwargs)
        d.callback(value)
    reactor.callLater(seconds, fire)
    return d

def print_stuff(message):
    # Because 'print' is a *statement*.
    print message

d = run_later(2, print_stuff, 'Hello')
d.addCallback(lambda ignored: run_later(3, print_stuff, 'World'))

run_later(3, print_stuff, 'Beautiful')

reactor.run()
</pre>

<p>
This will print "Hello" at two seconds, "Beautiful" at three seconds and
"World" three seconds after "Hello".
</p>

<p>
The deferreds here make sure that one thing happens after another. The 'World'
callback runs only after the deferred returned by the 'Hello' run_later is
fired.
</p>

<p>
The "concurrency" here, such as it is, only works because everything runs very
quickly. If any method called by the reactor blocks, then the entire
application blocks:
</p>

<pre class="python">
import time
from twisted.internet import defer, reactor

def sleep_then_print(seconds, value):
    time.sleep(seconds)
    print value

d = run_later(2, print_stuff, 'Hello')
d.addCallback(lambda ignored: sleep_then_print(3, 'World'))

run_later(3, print_stuff, 'Beautiful')

reactor.run()
</pre>

<p>
  Although this <em>looks</em> like it might do the same thing as the previous
program, it will actually display:
</p>

<pre>
Hello
World
Beautiful
</pre>

<p>
What happens is that after 'Hello' is printed, the 'sleep_then_print' callback
is fired, blocking processing for three seconds. The reactor only gets a
chance to execute the 'Beautiful' print statement after sleep_then_print has
exited.
</p>

<p>
This is about as much as can be said about the reactor without introducing
Twisted's abstractions for I/O.
</p>

<h1>Separate Concerns</h1>

<p>
Twisted is fundamentally about doing asynchronous I/O â€” the fundamental
purpose of deferreds and the reactor is to make it easier to write programs
that communicate over the network asynchronously.
</p>

<p>
The first necessary part is an interface for handling very low-level events
and operations: this socket just got some data; the remote end disconnected;
write some data etc. In Twisted terminology, this is a <em>transport</em>.
There are transports for TCP, UDP, UNIX sockets, processes and SSL. Each of
these knows how to read and write bytes to the wire.
</p>

<p>
The second part is an object that can provide meaning to the low-level byte
operations: a <em>protocol</em> object. The protocol is a state machine that
responds to events that the transport sends it, events like: <code>dataReceived</code>;
<code>connectionMade</code> and <code>connectionLost</code>.
</p>

<p>
The third is an object that can be used to create new protocol objects as new
connections are required and to bind these protocol objects to their
transports (not strictly true -- other parts of Twisted do the binding.
Still, it's a helpful lie). Twisted calls these <em>protocol factories</em>.
</p>

<p>
Now, let's combine all of these together to write a toy server and a client to
go with it.
</p>

<pre class="python">
from twisted.internet import protocol, reactor
from twisted.protocols.basic import (
   LineReceiver)

class ReverseLineProtocol(LineReceiver):
    """Line-based protocol that echoes any lines it receives in reverse.

    Disconnects the client when ten lines have been received.
    """

    def __init__(self):
        self._lines_received = 0

    def lineReceived(self, line):
        self.sendLine(''.join(reversed(line)))
        self._lines_received += 1
        if self._lines_received >= 10:
            self.transport.loseConnection()

class ReverseLineFactory(
    protocol.ServerFactory):

    protocol = ReverseLineProtocol


reactor.listenTCP(9999, ReverseLineFactory())
reactor.run()
</pre>

<p>
The protocol is a LineReceiver, which is a simple helper built on top of the
base protocol that buffers bytes until they become lines, and then sends those
lines to lineReceived.
</p>

<p>
The call to listenTCP binds that instance of the factory to listen on port
9999. When a new connection is made, Twisted constructs an instance of the
protocol and binds it to the socket opened for that connection.
</p>

<p>
Here's the client:
</p>

<pre class="python">
from twisted.internet import defer, reactor, protocol as proto
from twisted.protocols.basic import LineReceiver

class ReverseClientProtocol(LineReceiver):

    def __init__(self, deferred, string):
        self._deferred = deferred
        self._string = string

    def connectionMade(self):
        self.sendLine(self._string)

    def lineReceived(self, line):
        if self._deferred is None:
            return
        d, self._deferred = self.deferred, None
        d.callback(line)


class RemoteReverser:

    def __init__(self, host, port):
        self._host = host
        self._port = port

    def reverse(self, some_string):
        """Send 'some_string' to the host to be reversed."""
        d = defer.Deferred()
        client_creator = proto.ClientFactory(
            reactor, ReverseClientProtocol, d, some_string)
        client_creator.connectTCP(self._host, self._port)
        return d


def print_stuff(message):
    print message


reverser = RemoteReverser('localhost', 9999)
d = reverser.reverse('Hello')
d.addCallback(print_stuff)
d.addBoth(reactor.stop)

reactor.run()
</pre>

<p>
The ReverseLineProtocol implements the details of talking to the server: it
sends a line on connection and then fires its deferred as soon as it receives
a line back.
</p>

<p>
The dance with setting self._deferred to None is actually quite important. If
lineReceived naively fired the deferred every time it was called, then it
would raise an AlreadyFiredError.
</p>

<p>
RemoteReverser is a user-defined class with no explicit place in Twisted. It
provides an API for reversing a string. 'reverse' returns a deferred that will
fire with the first line returned from the server.
</p>

<p>
Again, by calling 'reverse' and using the deferred, callers can avoid knowing
<em>anything</em> about how the protocol works or what events are involved. As
far as a caller is concerned, a call to 'reverse' simply returns a placeholder
for a value that you don't have yet.
</p>

<h1>Conclusion</h1>

<p>
Twisted provides tools for building libraries and applications that are built
around asynchronous I/O. It tries hard not to make decisions for you so that
you can write whatever application you need.
</p>

<p>
  <a href="http://twistedmatrix.com/documents/current/">More
    documentation</a>,
    and <a href="http://twistedmatrix.com/documents/current/core/howto/defer-intro.html">a
    better version</a> of this document, is available on the Twisted web site.
</p>

  </body>
</html>
